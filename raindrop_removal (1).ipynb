{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLUXV-RRFUl2",
        "outputId": "b8b9da26-c474-48a4-eb8e-1f8c3fed4021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install einops timm tqdm scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torch.utils.data import random_split\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import zipfile\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "RnBO0P6DGHF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Res FFT-Conv Block"
      ],
      "metadata": {
        "id": "VuBeNH8jGRjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResFFTConvBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fft = torch.fft.fft2(x)\n",
        "        amp = torch.abs(fft)\n",
        "        phase = torch.angle(fft)\n",
        "\n",
        "        # Process amplitude\n",
        "        amp = self.conv1(amp)\n",
        "        amp = F.relu(self.conv2(amp))\n",
        "\n",
        "        # Reconstruct FFT with modified amp but original phase\n",
        "        real = amp * torch.cos(phase)\n",
        "        imag = amp * torch.sin(phase)\n",
        "        fft_modified = torch.complex(real, imag)\n",
        "\n",
        "        out = torch.fft.ifft2(fft_modified).real\n",
        "        return out + x"
      ],
      "metadata": {
        "id": "lwJO6nz8GSkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define GC Block"
      ],
      "metadata": {
        "id": "Hn1Sw0mbGZVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv_mask = nn.Conv2d(in_channels, 1, 1)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels // 2, in_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "        input_x = x\n",
        "\n",
        "        context_mask = self.conv_mask(x).view(b, 1, -1)\n",
        "        context_mask = self.softmax(context_mask)\n",
        "        context = x.view(b, c, -1)\n",
        "        context = torch.bmm(context, context_mask.permute(0, 2, 1)).view(b, c, 1, 1)\n",
        "        transformed = self.transform(context)\n",
        "\n",
        "        return input_x + transformed\n"
      ],
      "metadata": {
        "id": "iGWZaIlhGaPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Full Model"
      ],
      "metadata": {
        "id": "XVidlF5IGfWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RaindropRemovalNet(nn.Module):\n",
        "    def __init__(self, channels=64, n_blocks=19, gc_blocks=5):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Conv2d(3, channels, 3, padding=1)\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResFFTConvBlock(channels) for _ in range(n_blocks)]\n",
        "        )\n",
        "        self.gc_blocks = nn.Sequential(\n",
        "            *[GCBlock(channels) for _ in range(gc_blocks)]\n",
        "        )\n",
        "        self.final = nn.Conv2d(channels, 3, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.gc_blocks(x)\n",
        "        x = self.final(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7QhO_KKfGgoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss & Metrics"
      ],
      "metadata": {
        "id": "GcNiy-hhGrH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def msed_loss(pred, target):\n",
        "    return F.mse_loss(pred, target)\n",
        "\n",
        "def msfr_loss(pred, target):\n",
        "    return F.l1_loss(torch.fft.fft2(pred).abs(), torch.fft.fft2(target).abs())\n",
        "\n",
        "def total_loss(pred, target, alpha=1.0, beta=0.05):\n",
        "    return alpha * F.mse_loss(pred, target) + beta * F.l1_loss(torch.fft.fft2(pred).abs(), torch.fft.fft2(target).abs())\n"
      ],
      "metadata": {
        "id": "Gp5J_j2tGsFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "supnHszAGxDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=5, resume=False):\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    if resume and os.path.exists(\"checkpoint.pth\"):\n",
        "        checkpoint = torch.load(\"checkpoint.pth\")\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        best_val_loss = checkpoint[\"best_val_loss\"]\n",
        "        print(f\"Resumed training from epoch {start_epoch}\")\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "\n",
        "        for img, gt in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            img, gt = img.to(device), gt.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(img)\n",
        "            loss = criterion(pred, gt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        print(f\"  Training Loss: {total / len(train_loader):.4f}\")\n",
        "\n",
        "        # --------- Validation ---------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for rain_img, clean_img in val_loader:\n",
        "                rain_img = rain_img.to(device)\n",
        "                clean_img = clean_img.to(device)\n",
        "\n",
        "                output = model(rain_img)\n",
        "                loss = criterion(output, clean_img)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # --------- Save Best Model ---------\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"best_raindrop_model.pth\")\n",
        "            print(\"Saved Best Model!\")\n",
        "\n",
        "        # --------- Save Latest Checkpoint ---------\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"best_val_loss\": best_val_loss,\n",
        "        }, \"checkpoint.pth\")\n"
      ],
      "metadata": {
        "id": "iQlslHBoGwuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "zip_path = \"/content/drive/MyDrive/raindrop_dataset.zip\"\n",
        "extract_path = \"/content/raindrop_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbQkHcAqHGhs",
        "outputId": "ab17eae0-407f-472c-dac4-24157104744a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the ZIPs\n",
        "train_zip = \"/content/raindrop_dataset/train.zip\"\n",
        "test_a_zip = \"/content/raindrop_dataset/test_a.zip\"\n",
        "test_b_zip = \"/content/raindrop_dataset/test_b.zip\"\n",
        "\n",
        "# Paths to extract them\n",
        "train_path = \"/content/raindrop_dataset/train\"\n",
        "test_a_path = \"/content/raindrop_dataset/test_a\"\n",
        "test_b_path = \"/content/raindrop_dataset/test_b\"\n",
        "\n",
        "# Extract function\n",
        "def extract(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted: {zip_path} → {extract_to}\")\n",
        "\n",
        "# Extract all\n",
        "extract(train_zip, train_path)\n",
        "extract(test_a_zip, test_a_path)\n",
        "extract(test_b_zip, test_b_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4mXHtAIHoP",
        "outputId": "fdc8cbe9-ec21-4871-e35b-94a1de81beaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted: /content/raindrop_dataset/train.zip → /content/raindrop_dataset/train\n",
            "Extracted: /content/raindrop_dataset/test_a.zip → /content/raindrop_dataset/test_a\n",
            "Extracted: /content/raindrop_dataset/test_b.zip → /content/raindrop_dataset/test_b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define path\n",
        "train_rain_path = \"/content/raindrop_dataset/train/train/data\"\n",
        "train_clean_path = \"/content/raindrop_dataset/train/train/gt\"\n",
        "\n",
        "test_a_rain_path = \"/content/raindrop_dataset/test_a/test_a/data\"\n",
        "test_a_clean_path = \"/content/raindrop_dataset/test_a/test_a/gt\"\n",
        "\n",
        "test_b_rain_path = \"/content/raindrop_dataset/test_b/test_b/data\"\n",
        "test_b_clean_path = \"/content/raindrop_dataset/test_b/test_b/gt\""
      ],
      "metadata": {
        "id": "uOohXZQlI6oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create pytorch dataset class\n",
        "class RaindropDataset(Dataset):\n",
        "    def __init__(self, rain_dir, clean_dir, transform=None):\n",
        "        self.rain_dir = rain_dir\n",
        "        self.clean_dir = clean_dir\n",
        "        self.transform = transform\n",
        "        self.rain_images = sorted([f for f in os.listdir(rain_dir) if f.endswith(('png', 'jpg'))])\n",
        "        self.clean_images = sorted([f for f in os.listdir(clean_dir) if f.endswith(('png', 'jpg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.rain_images), len(self.clean_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        rain_img_path = os.path.join(self.rain_dir, self.rain_images[idx])\n",
        "        clean_img_path = os.path.join(self.clean_dir, self.clean_images[idx])\n",
        "\n",
        "        rain_img = Image.open(rain_img_path).convert(\"RGB\")\n",
        "        clean_img = Image.open(clean_img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            rain_img = self.transform(rain_img)\n",
        "            clean_img = self.transform(clean_img)\n",
        "\n",
        "        return rain_img, clean_img\n"
      ],
      "metadata": {
        "id": "RbWo3gRZKNU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define transform and load dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "train_dataset = RaindropDataset(train_rain_path, train_clean_path, transform=transform)"
      ],
      "metadata": {
        "id": "HRuVu_w5KaTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training setup"
      ],
      "metadata": {
        "id": "sfcIWwx6K1nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 90% training, 10% validation\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_set, val_set = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "SFc3BaNnJKRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = RaindropRemovalNet(channels=64, n_blocks=8, gc_blocks=3).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "tNqm8inVK8vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "train(model, train_loader, val_loader, optimizer, total_loss, device, num_epochs=5, resume=True)"
      ],
      "metadata": {
        "id": "MV4J4xZjLByS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35149bfb-e327-4341-9044-3b13d6aec961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 194/194 [02:18<00:00,  1.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training Loss: 0.5479\n",
            "  Validation Loss: 0.4882\n",
            "Saved Best Model!\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 194/194 [02:16<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training Loss: 0.4912\n",
            "  Validation Loss: 0.4744\n",
            "Saved Best Model!\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 194/194 [02:16<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training Loss: 0.4813\n",
            "  Validation Loss: 0.4686\n",
            "Saved Best Model!\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 194/194 [02:15<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training Loss: 0.4747\n",
            "  Validation Loss: 0.4744\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 194/194 [02:15<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training Loss: 0.4729\n",
            "  Validation Loss: 0.4636\n",
            "Saved Best Model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving model\n",
        "torch.save(model.state_dict(), \"raindrop_model.pth\")"
      ],
      "metadata": {
        "id": "FBfuwrfPIgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss_value = 0\n",
        "    total_psnr = 0\n",
        "    total_ssim = 0\n",
        "    with torch.no_grad():\n",
        "        for img, gt in tqdm(loader, desc=\"Evaluating\"):\n",
        "            img, gt = img.to(device), gt.to(device)\n",
        "            pred = model(img)\n",
        "            loss = total_loss(pred, gt)\n",
        "            total_loss_value += loss.item()\n",
        "\n",
        "            # Convert tensors to NumPy arrays for PSNR/SSIM\n",
        "            pred_np = pred.cpu().numpy()\n",
        "            gt_np = gt.cpu().numpy()\n",
        "\n",
        "            for i in range(pred_np.shape[0]):\n",
        "                pred_img = pred_np[i].transpose(1, 2, 0)\n",
        "                gt_img = gt_np[i].transpose(1, 2, 0)\n",
        "\n",
        "                pred_img = (pred_img * 255).clip(0, 255).astype('uint8')\n",
        "                gt_img = (gt_img * 255).clip(0, 255).astype('uint8')\n",
        "\n",
        "                total_psnr += psnr(gt_img, pred_img, data_range=255)\n",
        "                total_ssim += ssim(gt_img, pred_img, data_range=255, channel_axis=2, win_size=7)\n",
        "\n",
        "    n_samples = len(loader.dataset)\n",
        "    avg_loss = total_loss_value / len(loader)\n",
        "    avg_psnr = total_psnr / n_samples\n",
        "    avg_ssim = total_ssim / n_samples\n",
        "\n",
        "    print(f\"\\nResults on Test Set:\")\n",
        "    print(f\"  Avg Loss:  {avg_loss:.4f}\")\n",
        "    print(f\"  Avg PSNR:  {avg_psnr:.2f} dB\")\n",
        "    print(f\"  Avg SSIM:  {avg_ssim:.4f}\")\n",
        "    return avg_loss, avg_psnr, avg_ssim"
      ],
      "metadata": {
        "id": "hvYatKwSlmlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup test loaders\n",
        "test_a_dataset = RaindropDataset(test_a_rain_path, test_a_clean_path, transform=transform)\n",
        "test_b_dataset = RaindropDataset(test_b_rain_path, test_b_clean_path, transform=transform)\n",
        "\n",
        "test_a_loader = DataLoader(test_a_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "test_b_loader = DataLoader(test_b_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Evaluate\n",
        "evaluate(model, test_a_loader, device)\n",
        "evaluate(model, test_b_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GziWkQyz9mGP",
        "outputId": "868b9843-7c27-4c2d-92bc-492e602c58da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 15/15 [00:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results on Test Set:\n",
            "  Avg Loss:  0.3285\n",
            "  Avg PSNR:  24.73 dB\n",
            "  Avg SSIM:  0.7977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 63/63 [00:17<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results on Test Set:\n",
            "  Avg Loss:  0.4467\n",
            "  Avg PSNR:  22.81 dB\n",
            "  Avg SSIM:  0.7506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.44665726498951985,\n",
              " np.float64(22.81078682848064),\n",
              " np.float64(0.7505623299978201))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual output check\n",
        "def visualize_sample(model, dataset, device, num_samples=4):\n",
        "    model.eval()\n",
        "    indices = random.sample(range(len(dataset)), num_samples)\n",
        "\n",
        "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        rain_img, clean_img = dataset[idx]\n",
        "        rain_input = rain_img.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(rain_input)\n",
        "\n",
        "        # Unnormalize and convert to displayable image\n",
        "        def unnormalize(img_tensor):\n",
        "            return (img_tensor * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "        pred_img = unnormalize(pred.squeeze(0).detach()).cpu().permute(1, 2, 0).numpy()\n",
        "        rain_np = unnormalize(rain_img).cpu().permute(1, 2, 0).numpy()\n",
        "        clean_np = unnormalize(clean_img).cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "        axs[i, 0].imshow(rain_np)\n",
        "        axs[i, 0].set_title(\"Rain Image\")\n",
        "        axs[i, 1].imshow(clean_np)\n",
        "        axs[i, 1].set_title(\"Ground Truth\")\n",
        "        axs[i, 2].imshow(pred_img)\n",
        "        axs[i, 2].set_title(\"Prediction\")\n",
        "\n",
        "        for j in range(3):\n",
        "            axs[i, j].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9qDq5S68EdFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_sample(model, test_a_dataset, device, num_samples=25)"
      ],
      "metadata": {
        "id": "_UF5VnqjdxGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_sample(model, test_b_dataset, device, num_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i6ZJMb7dqK8Y",
        "outputId": "e3a6ce5c-6b04-45b7-accf-ec331e80aada"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}