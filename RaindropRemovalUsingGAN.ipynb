{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2EWfNxBGfb7"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision scikit-image opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4SD1v4qKoKiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_S2V0PIG44U"
      },
      "outputs": [],
      "source": [
        "# PyTorch and Torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "import torchvision\n",
        "\n",
        "# Other utilities\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTCkNicB8pvB"
      },
      "outputs": [],
      "source": [
        "# Install and import PyDrive\n",
        "!pip install -U -q PyDrive2\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Authenticate and create PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download the shared zip file using its file ID\n",
        "file_id = '1eEVo6iMzP4z3MOIEuwrN28ajKa_G6l17'  # Replace with your file ID if needed\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('raindrop_data.zip')  # Save it locally in Colab\n",
        "\n",
        "# Create extraction path\n",
        "extract_path = \"/content/raindrop_dataset\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(\"raindrop_data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"‚úÖ Extraction complete at:\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhVHa8Bk_4ss"
      },
      "outputs": [],
      "source": [
        "# Paths to the ZIPs\n",
        "train_zip = \"/content/raindrop_dataset/train.zip\"\n",
        "test_a_zip = \"/content/raindrop_dataset/test_a.zip\"\n",
        "test_b_zip = \"/content/raindrop_dataset/test_b.zip\"\n",
        "\n",
        "# Paths to extract them\n",
        "train_path = \"/content/raindrop_dataset/train\"\n",
        "test_a_path = \"/content/raindrop_dataset/test_a\"\n",
        "test_b_path = \"/content/raindrop_dataset/test_b\"\n",
        "\n",
        "# Extract function\n",
        "def extract(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted: {zip_path} ‚Üí {extract_to}\")\n",
        "\n",
        "# Extract all\n",
        "extract(train_zip, train_path)\n",
        "extract(test_a_zip, test_a_path)\n",
        "extract(test_b_zip, test_b_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj6cJnHkAA3V"
      },
      "outputs": [],
      "source": [
        "#define path\n",
        "train_rain_path = \"/content/raindrop_dataset/train/train/data\"\n",
        "train_clean_path = \"/content/raindrop_dataset/train/train/gt\"\n",
        "\n",
        "test_a_rain_path = \"/content/raindrop_dataset/test_a/test_a/data\"\n",
        "test_a_clean_path = \"/content/raindrop_dataset/test_a/test_a/gt\"\n",
        "\n",
        "test_b_rain_path = \"/content/raindrop_dataset/test_b/test_b/data\"\n",
        "test_b_clean_path = \"/content/raindrop_dataset/test_b/test_b/gt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I1fEkWD-Uke"
      },
      "outputs": [],
      "source": [
        "#manually clearing gpu memory\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOq_VAC_-k_6"
      },
      "outputs": [],
      "source": [
        "# Add memory config\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNK9-bcu8o0c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset Class\n",
        "class ImageRestorationDataset(Dataset):\n",
        "    def __init__(self, input_dir, gt_dir, image_size=(256, 256)):\n",
        "        self.input_dir = input_dir\n",
        "        self.gt_dir = gt_dir\n",
        "        self.input_images = sorted(os.listdir(input_dir))\n",
        "        self.gt_images = sorted(os.listdir(gt_dir))\n",
        "        self.image_size = image_size  # (width, height)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load images\n",
        "        input_img = cv2.imread(os.path.join(self.input_dir, self.input_images[idx]))\n",
        "        gt_img = cv2.imread(os.path.join(self.gt_dir, self.gt_images[idx]))\n",
        "\n",
        "        # Resize to fixed size\n",
        "        input_img = cv2.resize(input_img, self.image_size)  # Resize to (W, H)\n",
        "        gt_img = cv2.resize(gt_img, self.image_size)\n",
        "\n",
        "        # Convert to float32 and normalize to [0,1]\n",
        "        input_img = input_img.astype('float32') / 255.0\n",
        "        gt_img = gt_img.astype('float32') / 255.0\n",
        "\n",
        "        # Convert to tensor and reorder dimensions to C x H x W\n",
        "        input_img = torch.from_numpy(input_img.transpose((2, 0, 1)))\n",
        "        gt_img = torch.from_numpy(gt_img.transpose((2, 0, 1)))\n",
        "\n",
        "        return input_img, gt_img\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = ImageRestorationDataset(\n",
        "    input_dir=train_rain_path,\n",
        "    gt_dir=train_clean_path,\n",
        "    image_size=(128, 128)  # You can change this to another fixed size if needed\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ3WZEWGBzgR"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "# # Import models\n",
        "# from models import generator as generator_module\n",
        "# from models import discriminator as discriminator_module\n",
        "\n",
        "# # Device-agnostic setup\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Initialize models\n",
        "# generator = generator_module.Generator().to(device)\n",
        "# discriminator = discriminator_module.Discriminator().to(device)\n",
        "\n",
        "# # Loss and Optimizers\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer_g = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "# optimizer_d = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "# # Training loop\n",
        "# num_epochs = 5\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     generator.train()\n",
        "#     discriminator.train()\n",
        "\n",
        "#     for i, (input_img, gt_img) in enumerate(train_loader):\n",
        "#         input_img = input_img.to(device)\n",
        "#         gt_img = gt_img.to(device)\n",
        "\n",
        "#         # Train Discriminator\n",
        "#         optimizer_d.zero_grad()\n",
        "\n",
        "\n",
        "#         mask_list, frame1, frame2, fake_img = generator(input_img)\n",
        "#         fake_img = fake_img.detach()\n",
        "\n",
        "#         _, real_pred = discriminator(gt_img)\n",
        "#         _, fake_pred = discriminator(fake_img)\n",
        "\n",
        "#         d_loss_real = criterion(real_pred, torch.ones_like(real_pred))\n",
        "#         d_loss_fake = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
        "#         d_loss = (d_loss_real + d_loss_fake) * 0.5\n",
        "#         d_loss.backward()\n",
        "#         optimizer_d.step()\n",
        "\n",
        "#         # Train Generator\n",
        "#         optimizer_g.zero_grad()\n",
        "#         _, fake_pred = discriminator(fake_img)\n",
        "#         g_loss_adv = criterion(fake_pred, torch.ones_like(fake_pred))\n",
        "#         g_loss_l1 = criterion(fake_img, gt_img)\n",
        "#         g_loss = g_loss_adv + g_loss_l1\n",
        "#         g_loss.backward()\n",
        "#         optimizer_g.step()\n",
        "\n",
        "#         if i % 10 == 0:\n",
        "#             print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
        "#                   f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "#     # Save generator weights after each epoch\n",
        "#     torch.save(generator.state_dict(), f\"gen_epoch_{epoch+1}.pkl\")\n",
        "\n",
        "# # Final save\n",
        "# torch.save(generator.state_dict(), \"gen.pkl\")\n",
        "# print(\"Saved generator weights as gen.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "from models import generator as generator_module\n",
        "from models import discriminator as discriminator_module\n",
        "from models.vgg_init import vgg_init, vgg\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize models\n",
        "generator = generator_module.Generator().to(device)\n",
        "discriminator = discriminator_module.Discriminator().to(device)\n",
        "\n",
        "# VGG model for perceptual loss\n",
        "vgg_model = vgg_init()\n",
        "vgg_loss_model = vgg(vgg_model).to(device)\n",
        "\n",
        "# Loss and Optimizers\n",
        "adv_criterion = nn.MSELoss()\n",
        "l1_criterion = nn.L1Loss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 25\n",
        "warmup_epochs = 5\n",
        "adv_weight_schedule = lambda epoch: min(1.0, (epoch - warmup_epochs + 1) / 5) if epoch >= warmup_epochs else 0.0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for i, (input_img, gt_img) in enumerate(train_loader):\n",
        "        input_img = input_img.to(device)\n",
        "        gt_img = gt_img.to(device)\n",
        "\n",
        "        # ------------------------\n",
        "        # Train Discriminator\n",
        "        # ------------------------\n",
        "        for _ in range(2):  # Train D twice per iteration\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, _, _, fake_img_d = generator(input_img)\n",
        "\n",
        "            _, real_pred = discriminator(gt_img)\n",
        "            _, fake_pred = discriminator(fake_img_d)\n",
        "\n",
        "            # Label smoothing\n",
        "            real_labels = torch.empty_like(real_pred).uniform_(0.9, 1.0)\n",
        "            fake_labels = torch.empty_like(fake_pred).uniform_(0.0, 0.1)\n",
        "\n",
        "            d_loss_real = adv_criterion(real_pred, real_labels)\n",
        "            d_loss_fake = adv_criterion(fake_pred, fake_labels)\n",
        "            d_loss = (d_loss_real + d_loss_fake) * 0.5\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "        # ------------------------\n",
        "        # Train Generator\n",
        "        # ------------------------\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        _, _, _, fake_img = generator(input_img)\n",
        "        _, fake_pred = discriminator(fake_img)\n",
        "\n",
        "        # L1 Loss\n",
        "        g_loss_l1 = l1_criterion(fake_img, gt_img)\n",
        "\n",
        "        # Perceptual Loss\n",
        "        gen_feat = vgg_loss_model(fake_img)\n",
        "        real_feat = vgg_loss_model(gt_img)\n",
        "        g_loss_percep = sum([F.l1_loss(gf, rf) for gf, rf in zip(gen_feat, real_feat)])\n",
        "\n",
        "        # Adversarial Loss\n",
        "        adv_weight = adv_weight_schedule(epoch)\n",
        "        g_loss_adv = adv_criterion(fake_pred, torch.ones_like(fake_pred))\n",
        "\n",
        "        # Total Generator Loss\n",
        "        g_loss = adv_weight * g_loss_adv + 100 * g_loss_l1 + 10 * g_loss_percep\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # Logging\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n",
        "                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
        "            print(f\"Discriminator Output (Real Mean): {real_pred.mean().item():.4f}, \"\n",
        "                  f\"(Fake Mean): {fake_pred.mean().item():.4f}\")\n",
        "\n",
        "    # Save model weights\n",
        "    os.makedirs('./weights', exist_ok=True)\n",
        "    torch.save(generator.state_dict(), f'./weights/gen_epoch_{epoch+1}.pkl')\n",
        "    torch.save(discriminator.state_dict(), f'./weights/disc_epoch_{epoch+1}.pkl')\n",
        "\n",
        "# Final save\n",
        "torch.save(generator.state_dict(), \"./weights/gen.pkl\")\n",
        "print(\"Training complete. Generator saved as gen.pkl\")\n"
      ],
      "metadata": {
        "id": "1GL0I0frdizf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXek7DnDAVWt"
      },
      "outputs": [],
      "source": [
        "# # Initialize the Generator\n",
        "# generator = generator_module.Generator().cuda()\n",
        "\n",
        "# # Load the pre-trained generator weights\n",
        "# generator.load_state_dict(torch.load('gen.pkl'))\n",
        "\n",
        "# # Initialize the Discriminator\n",
        "# discriminator = discriminator_module.Discriminator().cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_12iSkDoK_uq"
      },
      "outputs": [],
      "source": [
        "# # Loss function\n",
        "# import os\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "# # Optimizers for Generator and Discriminator\n",
        "# optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "# optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# # Training Loop\n",
        "# num_epochs = 10\n",
        "# for epoch in range(num_epochs):\n",
        "#     for i, (input_img, gt_img) in enumerate(train_loader):\n",
        "#         # Move to GPU\n",
        "#         input_img, gt_img = input_img.cuda(), gt_img.cuda()\n",
        "\n",
        "#         # Zero gradients\n",
        "#         optimizer_g.zero_grad()\n",
        "#         optimizer_d.zero_grad()\n",
        "\n",
        "#         # Forward pass through Generator\n",
        "#         _, _, _, gen_output = generator(input_img)\n",
        "\n",
        "#         # Discriminator predictions\n",
        "#         _, real_pred = discriminator(gt_img)\n",
        "#         _, fake_pred = discriminator(gen_output)\n",
        "\n",
        "#         # Generator loss (only updates generator)\n",
        "#         g_loss = criterion(fake_pred, torch.ones_like(fake_pred))  # Generator wants fake to be real\n",
        "#         g_loss.backward()\n",
        "#         optimizer_g.step()\n",
        "\n",
        "#         # Now train discriminator separately with detached fake_pred\n",
        "#         _, fake_pred_detached = discriminator(gen_output.detach())\n",
        "#         _, real_pred = discriminator(gt_img)\n",
        "\n",
        "#         # Discriminator loss\n",
        "#         real_loss = criterion(real_pred, torch.ones_like(real_pred))\n",
        "#         fake_loss = criterion(fake_pred_detached, torch.zeros_like(fake_pred_detached))\n",
        "#         d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "#         # Backprop and optimize Discriminator\n",
        "#         d_loss.backward()\n",
        "#         optimizer_d.step()\n",
        "\n",
        "\n",
        "#         # Print losses for monitoring\n",
        "#         if i % 5 == 0:\n",
        "#             print(f\"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(train_loader)}], \"\n",
        "#                   f\"Loss G: {g_loss.item():.4f}, Loss D: {d_loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "#     # Create directory if it doesn't exist\n",
        "#     os.makedirs('./weights', exist_ok=True)\n",
        "\n",
        "#     # Save model weights after every epoch\n",
        "#     torch.save(generator.state_dict(), f'./weights/gen_epoch_{epoch}.pkl')\n",
        "#     torch.save(discriminator.state_dict(), f'./weights/disc_epoch_{epoch}.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKwaaWvZLDjA"
      },
      "outputs": [],
      "source": [
        "# def evaluate_model(test_loader):\n",
        "#     cumulative_psnr = 0\n",
        "#     cumulative_ssim = 0\n",
        "#     for i, (input_img, gt_img) in enumerate(test_loader):\n",
        "#         input_img, gt_img = input_img.cuda(), gt_img.cuda()\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             gen_output = generator(input_img)\n",
        "\n",
        "#         # Convert output to numpy arrays and compute metrics\n",
        "#         gen_output = gen_output.cpu().numpy().transpose((0, 2, 3, 1)) * 255.0\n",
        "#         gt_img = gt_img.cpu().numpy().transpose((0, 2, 3, 1)) * 255.0\n",
        "\n",
        "#         for j in range(input_img.size(0)):\n",
        "#             cur_psnr = calc_psnr(gen_output[j], gt_img[j])\n",
        "#             cur_ssim = calc_ssim(gen_output[j], gt_img[j])\n",
        "#             cumulative_psnr += cur_psnr\n",
        "#             cumulative_ssim += cur_ssim\n",
        "\n",
        "#     avg_psnr = cumulative_psnr / len(test_loader)\n",
        "#     avg_ssim = cumulative_ssim / len(test_loader)\n",
        "#     print(f\"Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}\")\n",
        "\n",
        "# # Test Dataset\n",
        "# test_dataset = ImageRestorationDataset(input_dir='/path/to/test_input/', gt_dir='/path/to/test_gt/')\n",
        "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# # Evaluate the model on test data\n",
        "# evaluate_model(test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define input and output directories\n",
        "#input_dir = '/content/drive/MyDrive/input/'  # <-- change this to your actual folder path\n",
        "output_dir = '/content/output/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "vzhb6Ss1eoE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xsjRySTdx9O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch libs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "\n",
        "# Tools\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Models\n",
        "from models import generator as generator_module\n",
        "\n",
        "\n",
        "def align_to_four(img):\n",
        "    h, w = img.shape[:2]\n",
        "    h_aligned = h - h % 4\n",
        "    w_aligned = w - w % 4\n",
        "    return img[:h_aligned, :w_aligned]\n",
        "\n",
        "\n",
        "def predict(image, model):\n",
        "    image = np.array(image, dtype='float32') / 255.\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    image = image[np.newaxis, :, :, :]\n",
        "    image = torch.from_numpy(image).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)[-1]\n",
        "\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose((0, 2, 3, 1))[0] * 255.\n",
        "    return output.astype('uint8')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Settings\n",
        "    input_dir = '/content/drive/MyDrive/input/'\n",
        "    output_dir = './output/'\n",
        "\n",
        "    # Load model\n",
        "    model = generator_module.Generator().cuda()\n",
        "    model.load_state_dict(torch.load('./weights/gen.pkl'))\n",
        "    model.eval()\n",
        "\n",
        "    # Make sure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Process images\n",
        "    input_list = sorted(os.listdir(input_dir))\n",
        "    for file_name in input_list:\n",
        "        print(f\"Processing image: {file_name}\")\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        output_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        img = cv2.imread(input_path)\n",
        "        img = align_to_four(img)\n",
        "\n",
        "        result = predict(img, model)\n",
        "\n",
        "        # Save output\n",
        "        cv2.imwrite(output_path, result)\n",
        "\n",
        "        # Display side-by-side\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Input Image\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Output (Derained)\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "loZrYWGnee5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from models import generator as generator_module\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def align_to_four(img):\n",
        "    h, w = img.shape[:2]\n",
        "    h_aligned = h - h % 4\n",
        "    w_aligned = w - w % 4\n",
        "    return img[:h_aligned, :w_aligned]\n",
        "\n",
        "def predict(image, model):\n",
        "    image = np.array(image, dtype='float32') / 255.\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    image = image[np.newaxis, :, :, :]\n",
        "    image = torch.from_numpy(image).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)[-1]\n",
        "\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose((0, 2, 3, 1))[0] * 255.\n",
        "    return output.astype('uint8')\n",
        "\n",
        "def calculate_psnr(pred, gt):\n",
        "    return compare_psnr(gt, pred, data_range=255)\n",
        "\n",
        "def calculate_ssim(pred, gt):\n",
        "    return compare_ssim(gt, pred, channel_axis=-1, data_range=255)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Updated paths\n",
        "    input_dir = '/content/raindrop_dataset/test_a/test_a/data/'\n",
        "    gt_dir = '/content/raindrop_dataset/test_a/test_a/gt/'\n",
        "    output_dir = './output/'\n",
        "\n",
        "    # Load model\n",
        "    model = generator_module.Generator().cuda()\n",
        "    model.load_state_dict(torch.load('./weights/gen.pkl'))\n",
        "    model.eval()\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    input_list = sorted(os.listdir(input_dir))\n",
        "    gt_list = sorted(os.listdir(gt_dir))  # Make sure GT list is sorted\n",
        "    total_psnr = 0\n",
        "    total_ssim = 0\n",
        "    processed_images = 0\n",
        "\n",
        "    # Ensure both input and GT lists have the same length\n",
        "    assert len(input_list) == len(gt_list), \"The number of input and GT images do not match.\"\n",
        "\n",
        "    for i, file_name in enumerate(input_list):\n",
        "        print(f\"\\nProcessing image: {file_name}\")\n",
        "\n",
        "        input_path = os.path.join(input_dir, file_name)\n",
        "        gt_path = os.path.join(gt_dir, gt_list[i])  # Get corresponding GT image by index\n",
        "        output_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        img = cv2.imread(input_path)\n",
        "        gt_img = cv2.imread(gt_path)\n",
        "\n",
        "        # Validate images\n",
        "        if img is None:\n",
        "            print(f\"‚ùå Failed to load input image: {input_path}\")\n",
        "            continue\n",
        "        if gt_img is None:\n",
        "            print(f\"‚ùå Failed to load GT image: {gt_path}\")\n",
        "            continue\n",
        "\n",
        "        img = align_to_four(img)\n",
        "        gt_img = align_to_four(gt_img)\n",
        "\n",
        "        result = predict(img, model)\n",
        "\n",
        "        # Save output\n",
        "        cv2.imwrite(output_path, result)\n",
        "\n",
        "        # Calculate PSNR & SSIM\n",
        "        psnr = calculate_psnr(result, gt_img)\n",
        "        ssim = calculate_ssim(result, gt_img)\n",
        "        print(f\"‚úÖ PSNR: {psnr:.2f} dB | SSIM: {ssim:.4f} for {file_name}\")\n",
        "\n",
        "        total_psnr += psnr\n",
        "        total_ssim += ssim\n",
        "        processed_images += 1\n",
        "\n",
        "    if processed_images > 0:\n",
        "        avg_psnr = total_psnr / processed_images\n",
        "        avg_ssim = total_ssim / processed_images\n",
        "        print(f\"\\nüìä Average PSNR: {avg_psnr:.2f} dB\")\n",
        "        print(f\"üìä Average SSIM: {avg_ssim:.4f}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No valid images processed. Please check your input/GT directories.\")\n"
      ],
      "metadata": {
        "id": "jFh67UC7JSz5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}